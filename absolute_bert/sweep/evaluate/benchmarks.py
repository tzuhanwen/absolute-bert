"""
é€™å€‹ module æŠŠ beir çš„ IR benchmark æµç¨‹å¯¦ä½œå®Œæ•´ä¸€é»žï¼Œåªè¦å¯¦ä½œ
SemiSiameseBiEncodeMethod å°±å¯ä»¥ä½¿ç”¨
"""

import logging
import os
from collections.abc import Sequence
from typing import Literal

from beir import util
from beir.datasets.data_loader import GenericDataLoader
from beir.retrieval.evaluation import EvaluateRetrieval
from beir.retrieval.search.dense import DenseRetrievalExactSearch as DRES

from absolute_bert.base_types import NestedMetricDict
from absolute_bert.bi_encoder import BiEncoder
from absolute_bert.formatter.metric import nest_a_metric_dict_tuple

logger = logging.getLogger(__name__)

try:
    import faiss
except ImportError:
    raise ImportError(
        "âŒ ç„¡æ³•è¼‰å…¥ `faiss` æ¨¡çµ„ã€‚è«‹å…ˆå®‰è£å®ƒæ‰èƒ½ç¹¼çºŒä½¿ç”¨ç›¸é—œ dense retrieval åŠŸèƒ½ã€‚\n\n"
        "è«‹æ ¹æ“šä½ çš„ç’°å¢ƒé¸æ“‡å®‰è£æ–¹å¼ï¼š\n"
        "ðŸ‘‰ CPU-only: pip install faiss-cpu\n"
        "ðŸ‘‰ GPU-enabled: pip install faiss-gpu\n"
        "ðŸ‘‰ conda (æ›´ç©©å®š)ï¼šconda install -c pytorch faiss-cpu\n"
    )


def _load_or_download_corpus(corpus_name="scifact", data_dir="data"):

    corpus, queries, qrels = None, None, None
    data_path = os.path.join(data_dir, corpus_name)

    try:
        corpus, queries, qrels = GenericDataLoader(data_folder=data_path).load(split="test")
    except ValueError:
        url = (
            f"https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/{corpus_name}.zip"
        )
        data_path = util.download_and_unzip(url, data_dir)
        print(data_path)
        corpus, queries, qrels = GenericDataLoader(data_folder=data_path).load(split="test")

    return corpus, queries, qrels


class BeirBenchmark:

    def __init__(self, corpus_name="scifact"):
        """
        corpus_name: scifact, trec-covid, nfcorpus
        """

        self.corpus_name = corpus_name
        self.corpus, self.queries, self.qrels = _load_or_download_corpus(corpus_name=corpus_name)

    def run(
        self,
        bi_encoder: BiEncoder,
        batch_size: int,
        score_fn_name: Literal["dot", "cos_sim"] = "cos_sim",
        k_values: Sequence[int] = (1, 3, 5, 10, 100, 1000),
        corpus_chunk_size=50000,
    ) -> NestedMetricDict:
        logger.info(f"running beir benchmark with {bi_encoder=}, scoring method `{score_fn_name}`")

        model = DRES(bi_encoder, batch_size=batch_size, corpus_chunk_size=corpus_chunk_size)

        retriever = EvaluateRetrieval(
            model, score_function=score_fn_name, k_values=k_values
        )  # or "dot" for dot product
        results = retriever.retrieve(self.corpus, self.queries)

        #### Evaluate your model with NDCG@k, MAP@K, Recall@K and Precision@K  where k = [1,3,5,10,100,1000]
        metric_tuple = retriever.evaluate(self.qrels, results, retriever.k_values)

        return nest_a_metric_dict_tuple(metric_tuple)
