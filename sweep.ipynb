{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# comment when exporting .py\n",
        "def is_colab():\n",
        "    try:\n",
        "        import google.colab\n",
        "        return True\n",
        "    except ImportError:\n",
        "        return False\n",
        "\n",
        "if is_colab():\n",
        "  !git clone https://github.com/adam840502/absolute-bert.git\n",
        "  import sys\n",
        "  sys.path.append('absolute-bert')\n",
        "  %cd absolute-bert/\n",
        "  !git fetch\n",
        "  !git checkout infra/wandb-logging\n",
        "  !pip install --quiet numpy pandas tqdm nltk beir omegaconf datasets wandb faiss-cpu"
      ],
      "metadata": {
        "id": "CFtJP0iD8sCn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7535b24e-0f5d-43b3-e3be-7476f330e886"
      },
      "id": "CFtJP0iD8sCn",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'absolute-bert' already exists and is not an empty directory.\n",
            "/content/absolute-bert\n",
            "Already on 'infra/wandb-logging'\n",
            "Your branch is up to date with 'origin/infra/wandb-logging'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# comment when exporting .py\n",
        "!mkdir -p configs"
      ],
      "metadata": {
        "id": "QbIul1LyAf1N"
      },
      "id": "QbIul1LyAf1N",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# {\n",
        "#   'tokenizer_type': tokenizer_type,\n",
        "#   'model': str(model),\n",
        "#   'model_params': str(model_params),\n",
        "\n",
        "\n",
        "#   # 'loss_type': str(using_loss),\n",
        "#   'loss_params': loss_params,\n",
        "# }"
      ],
      "metadata": {
        "id": "ZJeeyLJ11xbj"
      },
      "id": "ZJeeyLJ11xbj",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# comment when exporting .py\n",
        "%%writefile configs/default.yaml\n",
        "job_type: train\n",
        "epochs: 1\n",
        "masking_probability: 0.15\n",
        "max_length: 256\n",
        "random_seed: 42\n",
        "validation_portion: 0.9\n",
        "sampling_word_size: 100  # 用在 sampled softmax loss\n",
        "lr: 1e-4\n",
        "scheduler: cosine\n",
        "warmup_ratio: 0.1\n",
        "max_steps: -1\n",
        "clip_loss: 50\n",
        "\n",
        "model:\n",
        "  depth: 12\n",
        "  num_heads: 12\n",
        "  dim: 768\n",
        "  k_temperature: 0.5\n",
        "  # hidden_dim: 32\n",
        "  # embedding_initialize_method: 'rand'\n",
        "  # attention_type: Absolute_global_attention\n",
        "  # time_dim: 64\n",
        "\n",
        "batch_sizes:\n",
        "  train: 48\n",
        "  val: 128\n",
        "  IR: 32\n",
        "\n",
        "log_intervals:\n",
        "  train: 10\n",
        "  val: 500\n",
        "  params: 500\n",
        "  IR: 2000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "va7Iug8-87ek",
        "outputId": "3dd62182-4b12-451a-d8f3-c5db5b4f9b75"
      },
      "id": "va7Iug8-87ek",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting configs/default.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os\n",
        "from omegaconf import OmegaConf"
      ],
      "metadata": {
        "id": "fl_k40c28frj"
      },
      "id": "fl_k40c28frj",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # uncomment when exporting .py\n",
        "# parser = argparse.ArgumentParser()\n",
        "# parser.add_argument('--config', type=str, default='config.yaml')\n",
        "# args = parser.parse_args()\n",
        "\n",
        "# if os.path.exists(args.config):\n",
        "#     config = OmegaConf.load(args.config)\n",
        "# else:\n",
        "#     config = OmegaConf.load(\"configs/default.yaml\")  # 拆出來囉"
      ],
      "metadata": {
        "id": "mNgGcQRj3jFy"
      },
      "id": "mNgGcQRj3jFy",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# comment when exporting .py\n",
        "config = OmegaConf.load(\"configs/default.yaml\")\n",
        "config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gp3hX3mp_dFu",
        "outputId": "4c77f1a2-3fb9-4d3d-eaf5-8a072b10feec"
      },
      "id": "gp3hX3mp_dFu",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'job_type': 'train', 'epochs': 1, 'masking_probability': 0.15, 'max_length': 256, 'random_seed': 42, 'validation_portion': 0.9, 'sampling_word_size': 100, 'lr': 0.0001, 'scheduler': 'cosine', 'warmup_ratio': 0.1, 'max_steps': -1, 'clip_loss': 50, 'model': {'depth': 12, 'num_heads': 12, 'dim': 768, 'k_temperature': 0.5}, 'batch_sizes': {'train': 48, 'val': 128, 'IR': 32}, 'log_intervals': {'train': 10, 'val': 500, 'params': 500, 'IR': 2000}}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# comment when exporting .py\n",
        "dry_test = False"
      ],
      "metadata": {
        "id": "NUNdpGoR28By"
      },
      "id": "NUNdpGoR28By",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 主程式"
      ],
      "metadata": {
        "id": "fPfWjKsv_53U"
      },
      "id": "fPfWjKsv_53U"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5fBhjdKqETmk"
      },
      "id": "5fBhjdKqETmk",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "environmental-hearing",
      "metadata": {
        "tags": [],
        "id": "environmental-hearing"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "from datasets import load_from_disk\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AutoTokenizer, DataCollatorForLanguageModeling\n",
        "\n",
        "import wandb\n",
        "\n",
        "import absolute_bert.absolute_bert_outputAct as abs_bert\n",
        "import absolute_bert.mlm_losses as losses\n",
        "\n",
        "import torch.nn as nn\n",
        "from utils.evaluate import BeirBenchmark, BI_ENCODER_METHODS\n",
        "from utils.train import format_losses, MultiLossAverager\n",
        "from utils.logging import extract_param_stats"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mOQUvlAqSBQ",
        "outputId": "0b2e2d38-4f7d-45e2-bb94-20005024ae82"
      },
      "id": "6mOQUvlAqSBQ",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "sporting-sigma",
      "metadata": {
        "id": "sporting-sigma"
      },
      "outputs": [],
      "source": [
        "from transformers import get_cosine_schedule_with_warmup, get_linear_schedule_with_warmup\n",
        "\n",
        "schedulers = {\n",
        "  'cosine': get_cosine_schedule_with_warmup,\n",
        "  'linear': get_linear_schedule_with_warmup\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "abstract-grammar",
      "metadata": {
        "id": "abstract-grammar",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "b014d66b-a08a-42e6-f860-86c87bc86946"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33madam840502\u001b[0m (\u001b[33mghuang-nlp\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/absolute-bert/wandb/run-20250408_180045-8zzu4yw5</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ghuang-nlp/prototyping/runs/8zzu4yw5' target=\"_blank\">mild-shape-26</a></strong> to <a href='https://wandb.ai/ghuang-nlp/prototyping' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ghuang-nlp/prototyping' target=\"_blank\">https://wandb.ai/ghuang-nlp/prototyping</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ghuang-nlp/prototyping/runs/8zzu4yw5' target=\"_blank\">https://wandb.ai/ghuang-nlp/prototyping/runs/8zzu4yw5</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "run = wandb.init(entity = \"ghuang-nlp\",\n",
        "  project = \"prototyping\",\n",
        "  job_type = config.job_type,\n",
        "  group = config.scheduler,\n",
        "  tags = [config.job_type, config.scheduler],\n",
        "  config = OmegaConf.to_container(config, resolve=True),\n",
        "  mode = 'disabled' if dry_test else 'online',\n",
        "  save_code = True)"
      ]
    },
    {
      "cell_type": "raw",
      "id": "arctic-invalid",
      "metadata": {
        "tags": [],
        "id": "arctic-invalid"
      },
      "source": [
        "if not cfg.testing:  # save_before_train\n",
        "    temp_dir = get_saving_dir(cfg, model, for_initial=True)\n",
        "    if temp_dir:\n",
        "        trainer.save_model(temp_dir)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "artifact = run.use_artifact('ghuang-nlp/uncategorized/wikipedia.en-0.01:v0', type='dataset')\n",
        "artifact_dir = artifact.download()\n",
        "datadict = load_from_disk(artifact_dir)\n",
        "print(datadict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mpKz62wFLhy",
        "outputId": "d402916b-c525-491e-bf9f-f9d24571c111"
      },
      "id": "0mpKz62wFLhy",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact wikipedia.en-0.01:v0, 741.71MB. 8 files... \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   8 of 8 files downloaded.  \n",
            "Done. 0:0:1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['input_ids'],\n",
            "        num_rows: 1523836\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['input_ids'],\n",
            "        num_rows: 15141\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=True, mlm_probability=config.masking_probability)\n",
        "train_loader = DataLoader(datadict['train'], batch_size=config.batch_sizes.train, collate_fn=collator)\n",
        "val_loader = DataLoader(datadict['test'], batch_size=config.batch_sizes.val, collate_fn=collator)"
      ],
      "metadata": {
        "id": "60W-yoD5IUrF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10a68ec8-9932-4b6f-b4cd-e0a197da6027"
      },
      "id": "60W-yoD5IUrF",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = abs_bert.Absolute_bert_for_masked_LM(tokenizer.vocab_size, **config.model).to(device)\n",
        "loss_fn = losses.Cross_entropy(model)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "6HedrGZd1OOi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b534043c-f30c-48e6-d51e-6e2cea970e4e"
      },
      "id": "6HedrGZd1OOi",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Absolute_bert_for_masked_LM(\n",
            "  (base_model): Absolute_bert(\n",
            "    (embedding): Embedding(30522, 768)\n",
            "    (layers): ModuleList(\n",
            "      (0-7): 8 x Absolute_attention(\n",
            "        (Q): Linear(in_features=768, out_features=768, bias=False)\n",
            "        (K): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (V): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (O): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.5, inplace=False)\n",
            "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (linear_in): Linear(in_features=768, out_features=1536, bias=True)\n",
            "        (act_fn): GELU(approximate='tanh')\n",
            "        (linear_out): Linear(in_features=1536, out_features=768, bias=True)\n",
            "        (layer_norm_lin): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "optimizer_grouped_parameters = [\n",
        "  {\n",
        "    \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "    \"weight_decay\": 0.01,\n",
        "  },\n",
        "  {\n",
        "    \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "    \"weight_decay\": 0.0,\n",
        "  },\n",
        "]\n",
        "optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=config.lr)"
      ],
      "metadata": {
        "id": "dq9V26wCngKx"
      },
      "id": "dq9V26wCngKx",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scheduler = schedulers[config.scheduler](\n",
        "  optimizer,\n",
        "  num_warmup_steps = len(train_loader) * config.epochs * config.warmup_ratio,\n",
        "  num_training_steps = len(train_loader) * config.epochs,\n",
        ")"
      ],
      "metadata": {
        "id": "ReozypBFrTGI"
      },
      "id": "ReozypBFrTGI",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pure_text_token_vectors(output, inputs):\n",
        "  \"\"\"special_token and padding_token will map to zero vector.\"\"\"\n",
        "  mask = (inputs['attention_mask'] * (1 - inputs['special_tokens_mask'])).bool()\n",
        "  return output.masked_fill(~mask[:, :, None], 0.0)\n",
        "\n",
        "def tokenize_fn(texts):\n",
        "  inputs = tokenizer(texts, return_tensors='pt', padding=True, return_special_tokens_mask=True)\n",
        "  special_tokens_mask = inputs.pop('special_tokens_mask')\n",
        "  return inputs, {'special_tokens_mask': special_tokens_mask}\n",
        "\n",
        "model_output_method = BI_ENCODER_METHODS['bert_like_siamese_simple_pool'](\n",
        "  model,\n",
        "  tokenize_fn = tokenize_fn,\n",
        "  output_key = 0,\n",
        "  common_post_fn = pure_text_token_vectors,\n",
        "  aggregate_method = 'mean'\n",
        ")\n",
        "\n",
        "class StaticEmbeddingsWithTransform(nn.Module):\n",
        "  def __init__(self, model):\n",
        "    super().__init__()\n",
        "    self.model = model\n",
        "\n",
        "  def forward(self, **inputs):\n",
        "    return self.model.base_model.embedding(inputs['input_ids'])\n",
        "\n",
        "static_embeddings_method = BI_ENCODER_METHODS['bert_like_siamese_simple_pool'](\n",
        "  StaticEmbeddingsWithTransform(model).to(device),\n",
        "  tokenize_fn = tokenize_fn,\n",
        "  common_post_fn = pure_text_token_vectors,\n",
        "  aggregate_method = 'mean'\n",
        ")"
      ],
      "metadata": {
        "id": "8Yyo-hOj1ktA"
      },
      "id": "8Yyo-hOj1ktA",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "benchmark = BeirBenchmark(corpus_name='scifact', batch_size=config.batch_sizes.IR)\n",
        "\n",
        "# model_output_metrics = benchmark.run(model_output_method)\n",
        "# static_embeddings_metrics = benchmark.run(static_embeddings_method)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "6d86d33254f645c2a173802d0a5b35e9",
            "ecb6d93726144af19d620f89f9683761",
            "2c14d47a31e649b1b36807c3d79370ca",
            "06bfd5b27d484701bbfff45da2395eb3",
            "0dd529b63a854ad797f0c5bde22f8169",
            "2dbbdfd2b05e46aab5c61defe27261c0",
            "d0aac4a9daaf4e80abb800211af3ccec",
            "b4a0f235db2e486baad9ad544d99f362",
            "747050dfa79342df853de1fe5e08d89c",
            "ee38fce6eead40a1aa5080b11bd808b0",
            "e607e78108714d069813f317fbe76c17"
          ]
        },
        "id": "FgFmcFf13OkE",
        "outputId": "bd6b8861-9d2c-4fc4-da09-00f184e6375d"
      },
      "id": "FgFmcFf13OkE",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5183 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d86d33254f645c2a173802d0a5b35e9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_beir_log_dict(metric_dict, method_name):\n",
        "  return \\\n",
        "    {f\"{benchmark.corpus_name}-{method_name}/{k}\": v\n",
        "      for k, v in metric_dict.items()} | \\\n",
        "    {f\"highlight-{benchmark.corpus_name}-{method_name}/{k}\": v['10']\n",
        "      for k, v in metric_dict.items()}"
      ],
      "metadata": {
        "id": "-aVwyYxbSYA0"
      },
      "id": "-aVwyYxbSYA0",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "averager = MultiLossAverager()\n",
        "global_step = 0\n",
        "\n",
        "model.eval()\n",
        "wandb.log(\n",
        "  get_beir_log_dict(benchmark.run(model_output_method), 'model_output'),\n",
        "  step=global_step\n",
        ")\n",
        "wandb.log(\n",
        "  get_beir_log_dict(benchmark.run(static_embeddings_method), 'static_embeddings'),\n",
        "  step=global_step\n",
        ")\n",
        "wandb.log(extract_param_stats(\n",
        "        [\n",
        "          model.base_model.layers[0].layer_norm,\n",
        "          model.base_model.layers[-1].layer_norm,\n",
        "        ],\n",
        "        model\n",
        "      ))\n",
        "\n",
        "\n",
        "for epoch_num in range(config.epochs):\n",
        "\n",
        "  bar = tqdm(train_loader)\n",
        "  for batch_num, batch in enumerate(bar):\n",
        "\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    batch = {key: batch[key].to(device) for key in batch}\n",
        "    predicts, targets = model(**batch)\n",
        "\n",
        "    loss = loss_fn(predicts, targets)\n",
        "    final_loss, loss_dict = format_losses(loss, clip_value=config.clip_loss)\n",
        "\n",
        "    if global_step % config.log_intervals.train == 0:\n",
        "      wandb.log({f\"train/{k}\": v for k, v in loss_dict.items()}, step=global_step)\n",
        "\n",
        "    bar.set_postfix(loss_dict)\n",
        "\n",
        "    # with torch.autograd.detect_anomaly(True):\n",
        "      # loss.backward()\n",
        "      # torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=10, norm_type=2)\n",
        "\n",
        "    final_loss.backward()\n",
        "    optimizer.step()\n",
        "    global_step += 1\n",
        "    scheduler.step()\n",
        "\n",
        "    if global_step % config.log_intervals.val == 0:\n",
        "      model.eval()\n",
        "\n",
        "      with torch.no_grad():\n",
        "        val_bar = tqdm(val_loader, leave=False)\n",
        "        for batch in val_bar:\n",
        "          batch = {key: batch[key].to(device) for key in batch}\n",
        "          predicts, targets = model(**batch)\n",
        "          loss = loss_fn(predicts, targets)\n",
        "          _, loss_dict = format_losses(loss, clip_value=config.clip_loss)\n",
        "\n",
        "          batch_size = batch[\"labels\"].size(0)\n",
        "          averager.update(loss_dict, batch_size)\n",
        "\n",
        "          val_bar.set_postfix(loss_dict)\n",
        "\n",
        "      avg_losses = averager.compute()\n",
        "      wandb.log({f\"val/{k}\": v for k, v in avg_losses.items()}, step=global_step)\n",
        "      averager.reset()\n",
        "\n",
        "    if global_step % config.log_intervals.params == 0:\n",
        "      model.eval()\n",
        "      wandb.log(extract_param_stats(\n",
        "        [\n",
        "          model.base_model.layers[0].layer_norm,\n",
        "          model.base_model.layers[-1].layer_norm,\n",
        "        ],\n",
        "        model\n",
        "      ))\n",
        "\n",
        "    if global_step % config.log_intervals.IR == 0:\n",
        "      model.eval()\n",
        "      wandb.log(\n",
        "        get_beir_log_dict(benchmark.run(model_output_method), 'model_output'),\n",
        "        step=global_step\n",
        "      )\n",
        "      wandb.log(\n",
        "        get_beir_log_dict(benchmark.run(static_embeddings_method), 'static_embeddings'),\n",
        "        step=global_step\n",
        "      )\n",
        "\n",
        "\n",
        "    # del batch, loss\n",
        "\n",
        "    if (config.max_steps > 0) and (global_step > config.max_steps):\n",
        "      break\n",
        "\n",
        "  model.eval()\n",
        "  wandb.log(\n",
        "    get_beir_log_dict(benchmark.run(model_output_method), 'model_output') | {'epoch': epoch_num},\n",
        "    step=global_step\n",
        "  )\n",
        "  wandb.log(\n",
        "    get_beir_log_dict(benchmark.run(static_embeddings_method), 'static_embeddings') | {'epoch': epoch_num},\n",
        "    step=global_step\n",
        "  )"
      ],
      "metadata": {
        "id": "NzuC9h0E14Hg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442,
          "referenced_widgets": [
            "0e22cc891ab940079b8d06bfe10586f0",
            "60fbfd8090d34026a67a0972b86ca577",
            "856e2bb75cb742d28a522096cdda7217",
            "a1c1d409cfbd4464862cb6dba06a68ab",
            "ea979ca2fe0b4c11aa9967458ce393c2",
            "56932e3140c74d658d1f464f6117c6c2",
            "a01790ae70fd406999ead5d6adb4cbf7",
            "4d1932b050d24445912ec9f56d96828b",
            "90c605908b394bb1a756171cfc3067a5",
            "81d2351b8f7349e4be9372d8b0e0acd8",
            "c05ad0916126473ead226fdacf539489",
            "d7e74ec4f9904ed5bd9ee31387c9fa6c",
            "3c7c235a16684434bfce3941d7b9919d",
            "dc5a2c26b0bc4609b77faccf5a519d41",
            "02f318ffb9814c7883e6c9a34c817cf4",
            "74b355cd20704cd7ba37080499a6b60e",
            "0d5f6e8752144bd3bdc7129ed40b65ed",
            "172a0d4e0c5746a18694106a5d0cece5",
            "9aa3f6bf73b6425cba342a804ade1f2a",
            "3168b77a7be3490faf99750a73c5a0dd",
            "b71ba389d9cf4bcf8df09e431feb4944",
            "8745a3a31ef045e5a544a47681a3fb5a"
          ]
        },
        "outputId": "6b4509ef-5ffa-4eca-9dfd-775c972eb870"
      },
      "id": "NzuC9h0E14Hg",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/31747 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e22cc891ab940079b8d06bfe10586f0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/119 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d7e74ec4f9904ed5bd9ee31387c9fa6c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 500 that is less than the current step 501. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-7df74b9e2677>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mpredicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/absolute-bert/absolute_bert/absolute_bert_outputAct.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, labels, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/absolute-bert/absolute_bert/absolute_bert_outputAct.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/absolute-bert/absolute_bert/absolute_bert_outputAct.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tensor, attention_mask)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mintermediate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mlin_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_in\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm_lin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlin_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "experienced-python",
      "metadata": {
        "id": "experienced-python"
      },
      "outputs": [],
      "source": [
        "# model_artifact = wandb.Artifact(name=\"model\",\n",
        "#   type=\"model\",\n",
        "#   # description=\"trained with 2-1-training_with_msmarco\",\n",
        "#   metadata=training_args_config)\n",
        "# model_artifact.add_dir(saving_dir)\n",
        "# run.log_artifact(model_artifact)\n",
        "\n",
        "# run.log_code(**get_code_files_aggregating_functions(cfg.env.project_root))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "continental-rachel",
      "metadata": {
        "id": "continental-rachel"
      },
      "outputs": [],
      "source": [
        "# if not cfg.testing:\n",
        "#     if not os.path.exists(saving_dir):\n",
        "#         os.mkdir(saving_dir)\n",
        "\n",
        "#     trainer.save_model(saving_dir)\n",
        "#     trainer.save_state()\n",
        "#     torch.save(model, saving_dir/'pytorch.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "advisory-netherlands",
      "metadata": {
        "id": "advisory-netherlands"
      },
      "source": [
        "### for markdown recording"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "collective-laser",
      "metadata": {
        "id": "collective-laser"
      },
      "outputs": [],
      "source": [
        "# for polaritical_docs in zip(test_cossim_before, test_cossim_after):  # pos & neg\n",
        "#     print(f\"||{'|'.join(str(idx) for idx in range(10))}|\")\n",
        "#     for timepoint, values in zip(['before', 'after'], polaritical_docs):  # before & after\n",
        "#         print(f\"|{timepoint}|{'|'.join(f'{val:.4f}' for val in values.tolist())}|\")\n",
        "#     print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "divine-frontier",
      "metadata": {
        "id": "divine-frontier"
      },
      "outputs": [],
      "source": [
        "run.finish()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6d86d33254f645c2a173802d0a5b35e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ecb6d93726144af19d620f89f9683761",
              "IPY_MODEL_2c14d47a31e649b1b36807c3d79370ca",
              "IPY_MODEL_06bfd5b27d484701bbfff45da2395eb3"
            ],
            "layout": "IPY_MODEL_0dd529b63a854ad797f0c5bde22f8169"
          }
        },
        "ecb6d93726144af19d620f89f9683761": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2dbbdfd2b05e46aab5c61defe27261c0",
            "placeholder": "​",
            "style": "IPY_MODEL_d0aac4a9daaf4e80abb800211af3ccec",
            "value": "100%"
          }
        },
        "2c14d47a31e649b1b36807c3d79370ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4a0f235db2e486baad9ad544d99f362",
            "max": 5183,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_747050dfa79342df853de1fe5e08d89c",
            "value": 5183
          }
        },
        "06bfd5b27d484701bbfff45da2395eb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee38fce6eead40a1aa5080b11bd808b0",
            "placeholder": "​",
            "style": "IPY_MODEL_e607e78108714d069813f317fbe76c17",
            "value": " 5183/5183 [00:00&lt;00:00, 74685.49it/s]"
          }
        },
        "0dd529b63a854ad797f0c5bde22f8169": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2dbbdfd2b05e46aab5c61defe27261c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0aac4a9daaf4e80abb800211af3ccec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4a0f235db2e486baad9ad544d99f362": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "747050dfa79342df853de1fe5e08d89c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ee38fce6eead40a1aa5080b11bd808b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e607e78108714d069813f317fbe76c17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e22cc891ab940079b8d06bfe10586f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_60fbfd8090d34026a67a0972b86ca577",
              "IPY_MODEL_856e2bb75cb742d28a522096cdda7217",
              "IPY_MODEL_a1c1d409cfbd4464862cb6dba06a68ab"
            ],
            "layout": "IPY_MODEL_ea979ca2fe0b4c11aa9967458ce393c2"
          }
        },
        "60fbfd8090d34026a67a0972b86ca577": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56932e3140c74d658d1f464f6117c6c2",
            "placeholder": "​",
            "style": "IPY_MODEL_a01790ae70fd406999ead5d6adb4cbf7",
            "value": "  2%"
          }
        },
        "856e2bb75cb742d28a522096cdda7217": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d1932b050d24445912ec9f56d96828b",
            "max": 31747,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_90c605908b394bb1a756171cfc3067a5",
            "value": 624
          }
        },
        "a1c1d409cfbd4464862cb6dba06a68ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81d2351b8f7349e4be9372d8b0e0acd8",
            "placeholder": "​",
            "style": "IPY_MODEL_c05ad0916126473ead226fdacf539489",
            "value": " 624/31747 [04:06&lt;2:45:55,  3.13it/s, loss=7.11, final_loss=7.11]"
          }
        },
        "ea979ca2fe0b4c11aa9967458ce393c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56932e3140c74d658d1f464f6117c6c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a01790ae70fd406999ead5d6adb4cbf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d1932b050d24445912ec9f56d96828b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90c605908b394bb1a756171cfc3067a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "81d2351b8f7349e4be9372d8b0e0acd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c05ad0916126473ead226fdacf539489": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7e74ec4f9904ed5bd9ee31387c9fa6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3c7c235a16684434bfce3941d7b9919d",
              "IPY_MODEL_dc5a2c26b0bc4609b77faccf5a519d41",
              "IPY_MODEL_02f318ffb9814c7883e6c9a34c817cf4"
            ],
            "layout": "IPY_MODEL_74b355cd20704cd7ba37080499a6b60e"
          }
        },
        "3c7c235a16684434bfce3941d7b9919d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d5f6e8752144bd3bdc7129ed40b65ed",
            "placeholder": "​",
            "style": "IPY_MODEL_172a0d4e0c5746a18694106a5d0cece5",
            "value": " 99%"
          }
        },
        "dc5a2c26b0bc4609b77faccf5a519d41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9aa3f6bf73b6425cba342a804ade1f2a",
            "max": 119,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3168b77a7be3490faf99750a73c5a0dd",
            "value": 119
          }
        },
        "02f318ffb9814c7883e6c9a34c817cf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b71ba389d9cf4bcf8df09e431feb4944",
            "placeholder": "​",
            "style": "IPY_MODEL_8745a3a31ef045e5a544a47681a3fb5a",
            "value": " 118/119 [00:44&lt;00:00,  2.64it/s, loss=7.65, final_loss=7.65]"
          }
        },
        "74b355cd20704cd7ba37080499a6b60e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "0d5f6e8752144bd3bdc7129ed40b65ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "172a0d4e0c5746a18694106a5d0cece5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9aa3f6bf73b6425cba342a804ade1f2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3168b77a7be3490faf99750a73c5a0dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b71ba389d9cf4bcf8df09e431feb4944": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8745a3a31ef045e5a544a47681a3fb5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}