{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6baba7de-42e5-42ed-8d34-055857e52a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gensim scipy==1.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "359223f1-d317-43a1-be68-4b773357ee36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9868a467-07ba-4294-98a9-0494580542db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/miniconda3/envs/lima/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from utils.preprocessor import Stopwords_preprocessor\n",
    "from utils.logging import beir_metrics_to_markdown_table\n",
    "from IPython.display import Markdown\n",
    "\n",
    "# from rank_bm25 import BM25Okapi as BM25\n",
    "from transformers import logging, AutoTokenizer\n",
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "from beir.retrieval.evaluation import EvaluateRetrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cace617d-0c06-41a1-a705-d5e118a859de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecedc775-7d5d-46d8-ada5-51dc9f93fdb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 5183/5183 [00:00<00:00, 115001.50it/s]\n"
     ]
    }
   ],
   "source": [
    "corpus_name = 'scifact'\n",
    "# corpus_name = 'trec-covid'\n",
    "# corpus_name = 'nfcorpus'\n",
    "\n",
    "corpus, queries, qrels = GenericDataLoader(f'data/{corpus_name}').load(split=\"test\")\n",
    "corpus_text = [v['text'] for k,v in corpus.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74415317-b92a-41ba-857d-a6fc32f1e611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tokenize(x):\n",
    "#     return tokenizer.convert_ids_to_tokens(tokenizer.encode(x, add_special_tokens=False))\n",
    "\n",
    "# vectorizer = TfidfVectorizer(tokenizer=tokenize, vocabulary=tokenizer.vocab)\n",
    "# %time vectorizer.fit(corpus_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae78eab6-213d-42cb-8c83-bdb7656e4aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.7 s, sys: 345 ms, total: 22.1 s\n",
      "Wall time: 22 s\n"
     ]
    }
   ],
   "source": [
    "from gensim import models\n",
    "from gensim.utils import tokenize\n",
    "\n",
    "%time model = models.KeyedVectors.load_word2vec_format('data/glove.6B.100d_w2vformat_bash.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8afab6a5-e82d-4247-824b-06d117a37f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_vector(text, dim=300):\n",
    "\n",
    "    def fetch_vec(word):\n",
    "        try:\n",
    "            vec = model[word.lower()]\n",
    "        except KeyError:\n",
    "            vec = np.zeros([dim])\n",
    "        return vec\n",
    "    \n",
    "    word_vecs = [fetch_vec(word) for word in tokenize(text)]\n",
    "    try:\n",
    "        word_vecs = np.stack(word_vecs)\n",
    "    except: \n",
    "        print(text)\n",
    "        print(np.unique([len(v) for v in word_vecs]))\n",
    "    return np.mean(word_vecs, axis=0)\n",
    "\n",
    "def idf_mean_vector(text):\n",
    "    return np.einsum('ld,l', mean_vector(text), vectorizer.idf_[ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1aec96e1-6362-47df-a6e8-7bba46b04a41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.09 s, sys: 85.6 ms, total: 3.18 s\n",
      "Wall time: 3.18 s\n",
      "CPU times: user 18.9 ms, sys: 0 ns, total: 18.9 ms\n",
      "Wall time: 18.9 ms\n"
     ]
    }
   ],
   "source": [
    "dim = 100\n",
    "method = idf_mean_vector\n",
    "method = mean_vector\n",
    "\n",
    "%time text_vec_dict = OrderedDict({k: method(v['text'], dim) for k, v in corpus.items()})\n",
    "%time query_vec_dict = OrderedDict({k: method(v, dim) for k, v in queries.items()})\n",
    "text_vecs = np.stack(list(text_vec_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f10e4e1b-5b47-4be7-8231-a18caf29ca39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.4 s, sys: 1min 16s, total: 1min 37s\n",
      "Wall time: 1.84 s\n",
      "NDCG@1\tNDCG@3\tNDCG@5\tNDCG@10\tNDCG@100\tNDCG@1000\tMAP@1\tMAP@3\tMAP@5\tMAP@10\tMAP@100\tMAP@1000\tRecall@1\tRecall@3\tRecall@5\tRecall@10\tRecall@100\tRecall@1000\tP@1\tP@3\tP@5\tP@10\tP@100\tP@1000\n",
      "0.12\t0.15543\t0.17567\t0.19194\t0.23819\t0.2819\t0.11667\t0.14431\t0.15589\t0.16219\t0.17033\t0.17172\t0.11667\t0.18167\t0.23\t0.28056\t0.50778\t0.86072\t0.12\t0.06444\t0.04867\t0.03\t0.00563\t0.00097\n",
      "||NDCG|MAP|Recall|P|\n",
      "|-|-|-|-|-|\n",
      "|@1|0.1200|0.1167|0.1167|0.1200|\n",
      "|@3|0.1554|0.1443|0.1817|0.0644|\n",
      "|@5|0.1757|0.1559|0.2300|0.0487|\n",
      "|@10|0.1919|0.1622|0.2806|0.0300|\n",
      "|@100|0.2382|0.1703|0.5078|0.0056|\n",
      "|@1000|0.2819|0.1717|0.8607|0.0010|\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "||NDCG|MAP|Recall|P|\n",
       "|-|-|-|-|-|\n",
       "|@1|0.1200|0.1167|0.1167|0.1200|\n",
       "|@3|0.1554|0.1443|0.1817|0.0644|\n",
       "|@5|0.1757|0.1559|0.2300|0.0487|\n",
       "|@10|0.1919|0.1622|0.2806|0.0300|\n",
       "|@100|0.2382|0.1703|0.5078|0.0056|\n",
       "|@1000|0.2819|0.1717|0.8607|0.0010|"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = 'euclidean'\n",
    "metric = 'cosine'\n",
    "\n",
    "\n",
    "def score(query_vector, metric=metric):\n",
    "    return (1/pairwise_distances(query_vector[None, :], text_vecs, metric=metric))[0]\n",
    "\n",
    "\n",
    "%time results = {qid: dict(zip(text_vec_dict.keys(), score(query_vector).tolist())) \\\n",
    "            for qid, query_vector in query_vec_dict.items()}\n",
    "\n",
    "metrics = EvaluateRetrieval.evaluate(qrels, results, [1, 3, 5, 10, 100, 1000])\n",
    "\n",
    "flatten_metrics = {k: v for metric_type in metrics for k, v in metric_type.items()}\n",
    "metric_names, metric_values = zip(*flatten_metrics.items())\n",
    "print(*metric_names, sep='\\t')\n",
    "print(*metric_values, sep='\\t')\n",
    "\n",
    "md = beir_metrics_to_markdown_table(*metrics)\n",
    "print(md)\n",
    "Markdown(md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a56ff0-19e0-41a9-871e-4e63180ff4ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
